import os
import re
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

from Base.Base import Base
from ModuleFolders.LLMRequester.LLMRequester import LLMRequester
from ModuleFolders.TaskConfig.TaskConfig import TaskConfig
from ModuleFolders.TaskConfig.TaskType import TaskType
from ModuleFolders.TaskExecutor.TranslatorUtil import get_source_language_for_file
from ModuleFolders.ResponseExtractor.ResponseExtractor import ResponseExtractor
from ModuleFolders.ResponseChecker.ResponseChecker import ResponseChecker
from ModuleFolders.PromptBuilder.PromptBuilder import PromptBuilder
from ModuleFolders.PromptBuilder.PromptBuilderPolishing import PromptBuilderPolishing
from ModuleFolders.NERProcessor.NERProcessor import NERProcessor

# ç®€æ˜“è¯·æ±‚å™¨
class SimpleExecutor(Base):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


        # è®¢é˜…æ¥å£æµ‹è¯•å¼€å§‹äº‹ä»¶
        self.subscribe(Base.EVENT.API_TEST_START, self.api_test_start)
        # è®¢é˜…æœ¯è¯­è¡¨ç¿»è¯‘å¼€å§‹äº‹ä»¶
        self.subscribe(Base.EVENT.GLOSS_TASK_START, self.glossary_translation_start)
        # è®¢é˜…è¡¨æ ¼ç¿»è¯‘ä»»åŠ¡äº‹ä»¶
        self.subscribe(Base.EVENT.TABLE_TRANSLATE_START, self.handle_table_translation_start)
        # è®¢é˜…è¡¨æ ¼æ¶¦è‰²ä»»åŠ¡äº‹ä»¶
        self.subscribe(Base.EVENT.TABLE_POLISH_START, self.handle_table_polish_start)
        # è®¢é˜…æœ¯è¯­æå–ä»»åŠ¡äº‹ä»¶
        self.subscribe(Base.EVENT.TERM_EXTRACTION_START, self.handle_term_extraction_start)
        # è®¢é˜…æœ¯è¯­æå–ç¿»è¯‘äº‹ä»¶
        self.subscribe(Base.EVENT.TERM_TRANSLATE_SAVE_START, self.handle_term_translate_save_start)

    # å“åº”æ¥å£æµ‹è¯•å¼€å§‹äº‹ä»¶
    def api_test_start(self, event: int, data: dict):
        thread = threading.Thread(target = self.api_test, args = (event, data))
        thread.start()

    # æ¥å£æµ‹è¯•
    def api_test(self, event, data: dict):
        # è·å–å‚æ•°
        platform_tag = data.get("tag")
        platform_name = data.get("name")
        api_url = data.get("api_url")
        api_key = data.get("api_key")
        api_format = data.get("api_format")
        model_name = data.get("model")
        auto_complete = data.get("auto_complete")
        extra_body = data.get("extra_body",{})
        region = data.get("region")
        access_key = data.get("access_key")
        secret_key = data.get("secret_key")

        # è‡ªåŠ¨è¡¥å…¨APIåœ°å€
        if (platform_tag == "sakura" or platform_tag == "LocalLLM") and not api_url.endswith("/v1"):
            api_url += "/v1"
        elif auto_complete:
            version_suffixes = ["/v1", "/v2", "/v3", "/v4"]
            if not any(api_url.endswith(suffix) for suffix in version_suffixes):
                api_url += "/v1"

        # æµ‹è¯•ç»“æœ
        failure = []
        success = []

        # è§£æå¹¶åˆ†å‰²å¯†é’¥å­—ç¬¦ä¸²
        api_keys = re.sub(r"\s+","", api_key).split(",")

        # è½®è¯¢æ‰€æœ‰å¯†é’¥è¿›è¡Œæµ‹è¯•
        for api_key in api_keys:

            # æ„å»º Prompt
            messages = [
                {
                    "role": "user",
                    "content": "å°å¯çˆ±ï¼Œä½ åœ¨å¹²å˜›"
                }
            ]
            system_prompt = "ä½ æ¥ä¸‹æ¥è¦æ‰®æ¼”æˆ‘çš„å¥³æœ‹å‹ï¼Œåå­—å«æ¬£é›¨ï¼Œè¯·ä½ ä»¥å¥³æœ‹å‹çš„æ–¹å¼å›å¤æˆ‘ã€‚"

            # æ‰“å°æ—¥å¿—
            self.print("")
            self.info("æ­£åœ¨è¿›è¡Œæ¥å£æµ‹è¯• ...")
            self.info(f"æ¥å£åç§° - {platform_name}")
            self.info(f"æ¥å£åœ°å€ - {api_url}")
            self.info(f"æ¥å£å¯†é’¥ - {'*'*(len(api_key)-8)}{api_key[-8:]}") # éšè—æ•æ„Ÿä¿¡æ¯
            self.info(f"æ¨¡å‹åç§° - {model_name}")
            if extra_body:
                self.info(f"é¢å¤–å‚æ•° - {extra_body}")
            self.print(f"ç³»ç»Ÿæç¤ºè¯ - {system_prompt}")
            self.print(f"ä¿¡æ¯å†…å®¹ - {messages}")

            # æ„å»ºé…ç½®åŒ…
            platform_config = {
                "target_platform": platform_tag,
                "api_url": api_url,
                "api_key": api_key,
                "api_format": api_format,
                "model_name": model_name,
                "region":  region,
                "access_key":  access_key,
                "secret_key": secret_key,
                "extra_body": extra_body
            }

            #å°è¯•è¯·æ±‚
            requester = LLMRequester()
            skip, response_think, response_content, prompt_tokens, completion_tokens = requester.sent_request(
                messages,
                system_prompt,
                platform_config
            )

            # æµ‹è¯•æˆåŠŸ
            if skip == False:
                self.info("æ¥å£æµ‹è¯•æˆåŠŸ ...")
                self.info(f"æ¥å£è¿”å›ä¿¡æ¯ - {response_content}")
                # å‚¨å­˜ç»“æœ
                success.append(api_key)

            # æµ‹è¯•å¤±è´¥
            else:
                self.error(f"æ¥å£æµ‹è¯•å¤±è´¥ ... ")
                # å‚¨å­˜ç»“æœ
                failure.append(api_key)

            self.print("")

        # æ‰“å°ç»“æœ
        self.print("")
        self.info(f"æ¥å£æµ‹è¯•ç»“æœï¼šå…±æµ‹è¯• {len(api_keys)} ä¸ªæ¥å£ï¼ŒæˆåŠŸ {len(success)} ä¸ªï¼Œå¤±è´¥ {len(failure)} ä¸ª ...")
        if len(failure) >0:
            self.error(f"å¤±è´¥çš„æ¥å£å¯†é’¥ - {", ".join(failure)}")
        self.print("")

        # å‘é€å®Œæˆäº‹ä»¶
        self.emit(Base.EVENT.API_TEST_DONE, {
            "failure": failure,
            "success": success,
        })


    # å“åº”æœ¯è¯­è¡¨ç¿»è¯‘å¼€å§‹äº‹ä»¶
    def glossary_translation_start(self, event: int, data: dict):
        thread = threading.Thread(target = self.glossary_translation, args = (event, data))
        thread.start()

    # æœ¯è¯­è¡¨ç¿»è¯‘
    def glossary_translation(self, event, data: dict):

        # è·å–è¡¨æ ¼æ•°æ®
        prompt_dictionary_data = data.get("prompt_dictionary_data")
        if not prompt_dictionary_data:
            self.info("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„æœ¯è¯­")
            self.emit(Base.EVENT.GLOSS_TASK_DONE, {
                "status": "null",
                "updated_data": prompt_dictionary_data
            })
            return

        # è·å–æœªç¿»è¯‘æœ¯è¯­
        untranslated_items = [item for item in prompt_dictionary_data if not item.get("dst")]
        if not untranslated_items:
            self.info("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„æœ¯è¯­")
            self.emit(Base.EVENT.GLOSS_TASK_DONE, {
                "status": "null",
                "updated_data": prompt_dictionary_data
            })
            return

        # å‡†å¤‡ç¿»è¯‘é…ç½®
        config = TaskConfig()
        config.initialize()
        config.prepare_for_translation(TaskType.TRANSLATION)
        platform_config = config.get_platform_configuration("translationReq")
        target_language = config.target_language

        # åˆ†ç»„å¤„ç†ï¼ˆæ¯ç»„æœ€å¤š50ä¸ªï¼‰
        group_size = 50
        translated_count = 0
        total_groups = (len(untranslated_items) + group_size - 1) // group_size

        # è¾“å‡ºæ•´ä½“è¿›åº¦ä¿¡æ¯
        print("")
        self.info(f" å¼€å§‹æœ¯è¯­è¡¨å¾ªç¯ç¿»è¯‘ \n"
                f"â”œ æœªç¿»è¯‘æœ¯è¯­æ€»æ•°: {len(untranslated_items)}\n"
                f"â”œ åˆ†ç»„æ•°é‡: {total_groups}\n"
                f"â”” æ¯ç»„ä¸Šé™: {group_size}æœ¯è¯­")
        print("")

        # åˆ†ç»„ç¿»è¯‘å¤„ç†
        for group_idx in range(total_groups):
            start_idx = group_idx * group_size
            end_idx = start_idx + group_size
            current_group = untranslated_items[start_idx:end_idx]
            
            # ç»„å¤„ç†å¼€å§‹æ—¥å¿—
            print("")
            self.info(f" æ­£åœ¨å¤„ç†ç¬¬ {group_idx+1}/{total_groups} ç»„ \n"
                    f"â”œ æœ¬ç»„æœ¯è¯­èŒƒå›´: {start_idx+1}-{min(end_idx, len(untranslated_items))}\n"
                    f"â”” å®é™…å¤„ç†æ•°é‡: {len(current_group)}æœ¯è¯­")
            print("")

            # æ„é€ ç³»ç»Ÿæç¤ºè¯
            system_prompt = (
                f"Translate the source text from the glossary into {target_language} line by line, maintaining accuracy and naturalness, and output the translation wrapped in a textarea tag:\n"
                "<textarea>\n"
                f"1.{target_language} text\n"
                "</textarea>\n"
            )

            # æ„é€ æ¶ˆæ¯å†…å®¹ï¼ŒæŒ‰è¡Œæ’åˆ—ï¼Œå¹¶æ·»åŠ åºå·
            src_terms = [f"{idx+1}.{item['src']}" for idx, item in enumerate(current_group)]
            src_terms_text = "\n".join(src_terms)
            messages = [
                {
                    "role": "user",
                    "content": src_terms_text
                }
            ]

            # è¯·æ±‚å‘é€æ—¥å¿—
            print("")
            self.info(
                    f" æ­£åœ¨å‘é€APIè¯·æ±‚...\n"
                    f"â”” ç›®æ ‡è¯­è¨€: {target_language}")
            print("")

            # å‘é€ç¿»è¯‘è¯·æ±‚
            requester = LLMRequester()
            skip, _, response_content, _, _ = requester.sent_request(
                messages,
                system_prompt,
                platform_config
            )

            # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œè¿”å›å¤±è´¥ä¿¡æ¯
            if skip:
                self.error(f"ç¬¬ {group_idx+1}/{total_groups} ç»„ç¿»è¯‘å¤±è´¥")
                self.emit(Base.EVENT.GLOSS_TASK_DONE, {
                    "status": "error",
                    "message": f"ç¬¬ {group_idx+1} ç»„ç¿»è¯‘è¯·æ±‚å¤±è´¥",
                    "updated_data": None
                })
                return

            # å¦‚æœè¯·æ±‚æˆåŠŸï¼Œè§£æç¿»è¯‘ç»“æœ
            try:
                # æå–è¯‘æ–‡ç»“æœ
                textarea_contents = re.findall(r'<textarea.*?>(.*?)</textarea>', response_content, re.DOTALL)
                last_content = textarea_contents[-1]

                # åˆ†è¡Œ
                translated_terms = last_content.strip().split("\n")
                
                # å»é™¤åºå·
                translated_terms = [re.sub(r'^\d+\.', '', term).strip() for term in translated_terms]

                # æ£€æŸ¥ç¿»è¯‘ç»“æœæ•°é‡æ˜¯å¦åŒ¹é…
                if len(translated_terms) != len(current_group):
                    raise ValueError("ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…")
                    
            except Exception as e:
                self.error(f"ç¿»è¯‘ç»“æœè§£æå¤±è´¥: {str(e)}")
                self.emit(Base.EVENT.GLOSS_TASK_DONE, {
                    "status": "error",
                    "message": f"ç¬¬ {group_idx+1} ç»„ç»“æœè§£æå¤±è´¥",
                    "updated_data": None
                })
                return

            # æ›´æ–°ç¿»è¯‘ç»“æœ
            for idx, item in enumerate(current_group):
                item["dst"] = translated_terms[idx]
            translated_count += len(current_group)

            # è¿›åº¦æ›´æ–°æ—¥å¿—
            print("")
            self.info(
                    f"â”œ æœ¬ç»„å®Œæˆæ•°é‡: {len(current_group)}\n"
                    f"â”œ ç´¯è®¡å®Œæˆè¿›åº¦: {translated_count}/{len(untranslated_items)}\n"
                    f"â”” è¿›åº¦ç™¾åˆ†æ¯”: {translated_count/len(untranslated_items):.0%}")
            print("")

        # å…¨éƒ¨å®Œæˆ
        self.info(f" æœ¯è¯­è¡¨ç¿»è¯‘å…¨éƒ¨å®Œæˆ \n"
                f"â”œ æ€»å¤„ç†ç»„æ•°: {total_groups}\n"
                f"â”œ æ€»ç¿»è¯‘æœ¯è¯­: {translated_count}\n"
                f"â”” æœ€ç»ˆçŠ¶æ€: {'æˆåŠŸ' if translated_count == len(untranslated_items) else 'å¤±è´¥'}")
        
        # å‘é€å®Œæˆäº‹ä»¶
        self.emit(Base.EVENT.GLOSS_TASK_DONE, {
            "status": "success",
            "updated_data": prompt_dictionary_data
        })

    # å“åº”è¡¨æ ¼ç¿»è¯‘å¼€å§‹äº‹ä»¶ï¼Œå¹¶å¯åŠ¨æ–°çº¿ç¨‹
    def handle_table_translation_start(self, event, data: dict):
        thread = threading.Thread(target=self.process_table_translation, args=(data,), daemon=True)
        thread.start()

    # è¡¨æ ¼æ–‡æœ¬çš„åˆ†æ‰¹ç¿»è¯‘
    def process_table_translation(self, data: dict):
        """å¤„ç†è¡¨æ ¼æ–‡ä»¶çš„æ‰¹é‡ç¿»è¯‘ä»»åŠ¡"""
        # è§£åŒ…ä»UIä¼ æ¥çš„æ•°æ®
        file_path = data.get("file_path")
        items_to_translate = data.get("items_to_translate")
        language_stats = data.get("language_stats")

        # å‡†å¤‡ç¿»è¯‘é…ç½®
        config = TaskConfig()
        config.initialize()
        config.prepare_for_translation(TaskType.TRANSLATION)
        platform_config = config.get_platform_configuration("translationReq")
        file_source_lang = get_source_language_for_file(config.source_language, config.target_language, language_stats)

        # ç¿»è¯‘ä»»åŠ¡åˆ†å‰²
        MAX_LINES = 20  # æœ€å¤§è¡Œæ•°
        LOG_WIDTH = 50  # æ—¥å¿—æ¡†çš„ç»Ÿä¸€å®½åº¦
        total_items = len(items_to_translate)
        num_batches = (total_items + MAX_LINES - 1) // MAX_LINES

        self.info(f" å¼€å§‹å¤„ç†è¡¨æ ¼ç¿»è¯‘ä»»åŠ¡: {os.path.basename(file_path)}")
        self.info(f"    æ€»è®¡ {total_items} è¡Œæ–‡æœ¬, å°†åˆ†ä¸º {num_batches} ä¸ªæ‰¹æ¬¡å¤„ç†ã€‚")

        for i in range(num_batches):
            start_index = i * MAX_LINES
            end_index = start_index + MAX_LINES
            batch_items = items_to_translate[start_index:end_index]
            
            batch_num = i + 1
            log_header = f" æ‰¹æ¬¡ {batch_num}/{num_batches} "
            
            # æ„å»º0åŸºçš„æ•°å­—åºå·åŸæ–‡è¯å…¸
            source_text_dict = {str(idx): item['source_text'] for idx, item in enumerate(batch_items)}
            # æ„å»ºè¿˜åŸç”¨ç´¢å¼•åœ°å›¾
            index_map = [item['text_index'] for item in batch_items]

            # ä¸ºå½“å‰æ‰¹æ¬¡ä»»åŠ¡æ„å»ºæç¤ºè¯å†…å®¹
            messages, system_prompt, _ = PromptBuilder.generate_prompt(
                config, source_text_dict, [], file_source_lang
            )
            
            # æ—¥å¿—
            print(f"\nâ•”{'â•' * (LOG_WIDTH-2)}")
            print(f"â•‘{log_header.center(LOG_WIDTH-2)}")
            print(f"â• {'â•' * (LOG_WIDTH-2)}")
            print(f"â”œâ”€ æ­£åœ¨å‘é€è¯·æ±‚ (å…± {len(batch_items)} è¡Œ)...")
            
            # å‘é€è¯·æ±‚
            requester = LLMRequester()
            skip, _, response_content, _, _ = requester.sent_request(
                messages, system_prompt, platform_config
            )

            # æ£€æŸ¥è¯·æ±‚æ˜¯å¦å¤±è´¥
            if skip:
                print("â”œâ”€ è¯·æ±‚å¤±è´¥ï¼Œç½‘ç»œæˆ–APIå¯†é’¥é”™è¯¯ã€‚")
                print(f"â””â”€ âŒ è·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                continue

            # æ—¥å¿—è¾“å‡º
            print("â”œâ”€ æ”¶åˆ°å›å¤ï¼Œå†…å®¹å¦‚ä¸‹:")
            for line in response_content.strip().split('\n'):
                print(f"â”‚  {line}")
            print(f"â”œ{'â”€' * (LOG_WIDTH-2)}") # æ·»åŠ ä¸€ä¸ªåˆ†éš”çº¿

            # æå–å’Œæ£€æŸ¥è¿”å›å†…å®¹
            print("â”œâ”€ æ­£åœ¨è§£æå’Œæ ¡éªŒå›å¤...")
            response_dict = ResponseExtractor.text_extraction(self, source_text_dict, response_content)
            check_result, error_content = ResponseChecker.check_polish_response_content(self, config, response_content, response_dict, source_text_dict)
            
            if not check_result:
                print(f"â”œâ”€ å†…å®¹æ ¡éªŒå¤±è´¥: {error_content}")
                print(f"â””â”€ âŒ è·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                continue
            
            print(f"â”œâ”€ æˆåŠŸè§£æ {len(response_dict)} æ¡ç»“æœã€‚")

            # å°†å­—ç¬¦ä¸²åºå·çš„å­—å…¸è½¬æ¢å›åŸå§‹ text_index çš„å­—å…¸-
            restored_response_dict = {
                index_map[int(temp_idx_str)]: text
                for temp_idx_str, text in response_dict.items()
            }

            # ç§»é™¤æ–‡æœ¬ä¸­çš„æ•°å­—åºå·
            updated_items_for_ui = ResponseExtractor.remove_numbered_prefix(self, restored_response_dict)

            # å‘é€è¡¨æ ¼æ›´æ–°ä¿¡å·
            self.emit(Base.EVENT.TABLE_UPDATE, {
                "file_path": file_path,
                "target_column_index": 2,
                "updated_items": updated_items_for_ui
            })
            print(f"â””â”€ âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå·²å‘é€UIæ›´æ–°ã€‚")
            print("")

        # æ›´æ–°è½¯ä»¶çŠ¶æ€
        Base.work_status = Base.STATUS.IDLE 
        self.info(f" ğŸ³ è¡¨æ ¼ç¿»è¯‘ä»»åŠ¡å·²ç»å…¨éƒ¨å®Œæˆ")                            

    # å“åº”è¡¨æ ¼æ¶¦è‰²äº‹ä»¶
    def handle_table_polish_start(self, event, data: dict):
        thread = threading.Thread(target=self.process_table_polish, args=(data,), daemon=True)
        thread.start()

    # è¡¨æ ¼æ–‡æœ¬çš„åˆ†æ‰¹æ¶¦è‰²
    def process_table_polish(self, data: dict):
        """å¤„ç†è¡¨æ ¼æ–‡ä»¶çš„æ‰¹é‡ç¿»è¯‘ä»»åŠ¡"""
        # è§£åŒ…ä»UIä¼ æ¥çš„æ•°æ®
        file_path = data.get("file_path")
        items_to_polish = data.get("items_to_polish")

        # å‡†å¤‡ç¿»è¯‘é…ç½®
        config = TaskConfig()
        config.initialize()
        config.prepare_for_translation(TaskType.POLISH)
        platform_config = config.get_platform_configuration("polishingReq")
        polishing_mode_selection = config.polishing_mode_selection

        # ç¿»è¯‘ä»»åŠ¡åˆ†å‰²
        MAX_LINES = 20  # æœ€å¤§è¡Œæ•°
        LOG_WIDTH = 50  # æ—¥å¿—æ¡†çš„ç»Ÿä¸€å®½åº¦
        total_items = len(items_to_polish)
        num_batches = (total_items + MAX_LINES - 1) // MAX_LINES

        self.info(f" å¼€å§‹å¤„ç†è¡¨æ ¼æ¶¦è‰²ä»»åŠ¡: {os.path.basename(file_path)}")
        self.info(f"    æ€»è®¡ {total_items} è¡Œæ–‡æœ¬, å°†åˆ†ä¸º {num_batches} ä¸ªæ‰¹æ¬¡å¤„ç†ã€‚")

        for i in range(num_batches):
            start_index = i * MAX_LINES
            end_index = start_index + MAX_LINES
            batch_items = items_to_polish[start_index:end_index]
            
            batch_num = i + 1
            log_header = f" æ‰¹æ¬¡ {batch_num}/{num_batches} "
            
            # æ„å»º0åŸºçš„æ•°å­—åºå·åŸæ–‡è¯å…¸
            source_text_dict = {str(idx): item['source_text'] for idx, item in enumerate(batch_items)}
            # è¯‘æ–‡è¯å…¸
            translation_text_dict = {str(idx): item['translation_text'] for idx, item in enumerate(batch_items)}
            # æ„å»ºè¿˜åŸç”¨ç´¢å¼•åœ°å›¾
            index_map = [item['text_index'] for item in batch_items]

            # ç”Ÿæˆæç¤ºè¯å†…å®¹
            messages, system_prompt, extra_log = PromptBuilderPolishing.generate_prompt(
                config,
                source_text_dict,
                translation_text_dict,
                [],
            )
            
            # æ—¥å¿—
            print(f"\nâ•”{'â•' * (LOG_WIDTH-2)}")
            print(f"â•‘{log_header.center(LOG_WIDTH-2)}")
            print(f"â• {'â•' * (LOG_WIDTH-2)}")
            print(f"â”œâ”€ æ­£åœ¨å‘é€è¯·æ±‚ (å…± {len(batch_items)} è¡Œ)...")
            
            # å‘é€è¯·æ±‚
            requester = LLMRequester()
            skip, _, response_content, _, _ = requester.sent_request(
                messages, system_prompt, platform_config
            )

            # æ£€æŸ¥è¯·æ±‚æ˜¯å¦å¤±è´¥
            if skip:
                print("â”œâ”€ è¯·æ±‚å¤±è´¥ï¼Œç½‘ç»œæˆ–APIå¯†é’¥é”™è¯¯ã€‚")
                print(f"â””â”€ âŒ è·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                continue

            # æ—¥å¿—è¾“å‡º
            print("â”œâ”€ æ”¶åˆ°å›å¤ï¼Œå†…å®¹å¦‚ä¸‹:")
            for line in response_content.strip().split('\n'):
                print(f"â”‚  {line}")
            print(f"â”œ{'â”€' * (LOG_WIDTH-2)}") # æ·»åŠ ä¸€ä¸ªåˆ†éš”çº¿


            # æ ¹æ®æ¶¦è‰²æ¨¡å¼è°ƒæ•´æ–‡æœ¬å¯¹è±¡
            if polishing_mode_selection == "source_text_polish":
                text_dict = source_text_dict
            elif polishing_mode_selection == "translated_text_polish":
                text_dict = translation_text_dict

            # æå–å’Œæ£€æŸ¥è¿”å›å†…å®¹
            print("â”œâ”€ æ­£åœ¨è§£æå’Œæ ¡éªŒå›å¤...")
            response_dict = ResponseExtractor.text_extraction(self, text_dict, response_content)
            check_result, error_content = ResponseChecker.check_polish_response_content(self, config, response_content, response_dict, text_dict)
            
            if not check_result:
                print(f"â”œâ”€ å†…å®¹æ ¡éªŒå¤±è´¥: {error_content}")
                print(f"â””â”€ âŒ è·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                continue
            
            print(f"â”œâ”€ æˆåŠŸè§£æ {len(response_dict)} æ¡ç»“æœã€‚")

            # å°†å­—ç¬¦ä¸²åºå·çš„å­—å…¸è½¬æ¢å›åŸå§‹ text_index çš„å­—å…¸-
            restored_response_dict = {
                index_map[int(temp_idx_str)]: text
                for temp_idx_str, text in response_dict.items()
            }

            # ç§»é™¤æ–‡æœ¬ä¸­çš„æ•°å­—åºå·
            updated_items_for_ui = ResponseExtractor.remove_numbered_prefix(self, restored_response_dict)

            # å‘é€è¡¨æ ¼æ›´æ–°ä¿¡å·
            self.emit(Base.EVENT.TABLE_UPDATE, {
                "file_path": file_path,
                "target_column_index": 3,
                "updated_items": updated_items_for_ui
            })
            print(f"â””â”€ âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå·²å‘é€UIæ›´æ–°ã€‚")
            print("")

        # æ›´æ–°è½¯ä»¶çŠ¶æ€
        Base.work_status = Base.STATUS.IDLE 
        self.info(f" ğŸ³ è¡¨æ ¼æ¶¦è‰²ä»»åŠ¡å·²ç»å…¨éƒ¨å®Œæˆ")         

    # å“åº”æœ¯è¯­æå–äº‹ä»¶ï¼Œå¹¶å¯åŠ¨æ–°çº¿ç¨‹
    def handle_term_extraction_start(self, event, data: dict):
        thread = threading.Thread(target=self.process_term_extraction, args=(data,), daemon=True)
        thread.start()

    # æœ¯è¯­æå–å¤„ç†æ–¹æ³•
    def process_term_extraction(self, data: dict):
        params = data.get("params", {})
        items_data = data.get("items_data", [])

        if not items_data:
            self.warning("æœ¯è¯­æå–ä»»åŠ¡ä¸­æ­¢ï¼šæ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡æœ¬ã€‚")
            self.emit(Base.EVENT.TERM_EXTRACTION_DONE, {"results": []})
            return

        self.info(f"å¼€å§‹å¤„ç†æœ¯è¯­æå–ä»»åŠ¡... å‚æ•°: {params}")
        self.info(f"å…±æ”¶åˆ° {len(items_data)} æ¡å¾…å¤„ç†æ•°æ®ã€‚")

        # å®ä¾‹åŒ–ç‹¬ç«‹çš„å¤„ç†å™¨
        processor = NERProcessor()
        
        # è°ƒç”¨å¤„ç†å™¨çš„æ–¹æ³•ï¼Œä¼ å…¥æ­£ç¡®çš„å‚æ•°
        results = processor.extract_terms(
            items_data=items_data,
            model_name=params.get("model_name"), # ä½¿ç”¨ model_name
            entity_types=params.get("entity_types")
        )
        
        self.info(f"æœ¯è¯­æå–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} ä¸ªæœ¯è¯­ã€‚")

        # å·¥ä½œå®Œæˆåï¼Œå‘å°„å®Œæˆäº‹ä»¶å°†ç»“æœä¼ å›UIçº¿ç¨‹
        self.emit(Base.EVENT.TERM_EXTRACTION_DONE, {"results": results})


    # å“åº”ç¿»è¯‘å¹¶ä¿å­˜æœ¯è¯­è¡¨çš„äº‹ä»¶ï¼Œå¯åŠ¨æ–°çº¿ç¨‹
    def handle_term_translate_save_start(self, event, data: dict):
        thread = threading.Thread(target=self.process_term_translate_and_save, args=(data,), daemon=True)
        thread.start()

    def process_term_translate_and_save(self, data: dict):
        """
        ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æœ¯è¯­çš„ä¸Šä¸‹æ–‡ç¿»è¯‘å’Œä¿å­˜ä»»åŠ¡ã€‚
        """
        # æå–æ•°æ®
        extraction_results = data.get("extraction_results", [])
        if not extraction_results:
            self.warning("æœ¯è¯­ç¿»è¯‘ä»»åŠ¡ä¸­æ­¢ï¼šæœªæ”¶åˆ°ä»»ä½•æå–ç»“æœã€‚")
            self.emit(Base.EVENT.TERM_TRANSLATE_SAVE_DONE, {"status": "no_result", "message": "æœªæ”¶åˆ°æå–ç»“æœ"})
            return

        self.info("â–¶ï¸ å¼€å§‹æ‰§è¡Œã€åŸºäºä¸Šä¸‹æ–‡ç¿»è¯‘å¹¶ä¿å­˜æœ¯è¯­ã€‘ä»»åŠ¡...")

        # æå–æ‰€æœ‰å”¯ä¸€çš„â€œæ‰€åœ¨åŸæ–‡â€(context)
        unique_contexts = sorted(list(set(result['context'] for result in extraction_results)))
        if not unique_contexts:
            self.warning("æœ¯è¯­ç¿»è¯‘ä»»åŠ¡ä¸­æ­¢ï¼šæ²¡æœ‰æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡åŸæ–‡ã€‚")
            self.emit(Base.EVENT.TERM_TRANSLATE_SAVE_DONE, {"status": "no_result", "message": "æ²¡æœ‰æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡"})
            return

        # å‡†å¤‡ç¿»è¯‘é…ç½®
        config = TaskConfig()
        config.initialize()
        config.prepare_for_translation(TaskType.TRANSLATION)
        target_language = config.target_language
        # ä»é…ç½®ä¸­è·å–å®é™…çº¿ç¨‹æ•°
        max_threads = config.actual_thread_counts

        # å°†åŸæ–‡åˆ†æ‰¹å¤„ç†
        MAX_LINES = 20  # æ¯æ‰¹æœ€å¤§åŸæ–‡è¡Œæ•°
        LOG_WIDTH = 50  # æ—¥å¿—æ¡†ç»Ÿä¸€å®½åº¦
        total_items = len(unique_contexts)
        num_batches = (total_items + MAX_LINES - 1) // MAX_LINES

        # æ‰“å°æ•´ä½“ä»»åŠ¡ä¿¡æ¯
        print(f"\nâ•”{'â•' * (LOG_WIDTH-2)}")
        print(f"â•‘{'åŸºäºä¸Šä¸‹æ–‡çš„æœ¯è¯­ç¿»è¯‘ä¸ä¿å­˜'.center(LOG_WIDTH-2)}")
        print(f"â• {'â•' * (LOG_WIDTH-2)}")
        print(f"â”œâ”€ ç‹¬ç«‹ä¸Šä¸‹æ–‡æ€»æ•°: {total_items}")
        print(f"â”œâ”€ å°†åˆ†ä¸º {num_batches} ä¸ªæ‰¹æ¬¡å¤„ç†")
        print(f"â””â”€ ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ•°: {max_threads}")

        # å®šä¹‰ç”¨äºçº¿ç¨‹æ± çš„å·¥ä½œå‡½æ•°
        def process_batch(batch_contexts, batch_num, total_batches):
            """å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„è¯·æ±‚ã€è§£æå’Œè¿”å›ç»“æœ"""
            log_header = f" æ‰¹æ¬¡ {batch_num}/{total_batches} "
            print(f"\nâ•”{'â•' * (LOG_WIDTH-2)}")
            print(f"â•‘{log_header.center(LOG_WIDTH-2)}")
            print(f"â• {'â•' * (LOG_WIDTH-2)}")
            
            user_content = "\n".join(batch_contexts)
            system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æœ¯è¯­æå–ä¸ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œéµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š
1.  **è¯†åˆ«å…³é”®æœ¯è¯­**ï¼šä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ä¸“æœ‰åè¯ã€‚æœ¯è¯­ç±»å‹åŒ…æ‹¬ä½†ä¸é™äºï¼šäººåã€åœ°åã€ç»„ç»‡ã€ç‰©å“ã€è£…å¤‡ã€æŠ€èƒ½ã€é­”æ³•ã€ç§æ—ã€ç”Ÿç‰©ç­‰ã€‚
2.  **ç¿»è¯‘æœ¯è¯­**ï¼šå°†æ¯ä¸ªè¯†åˆ«å‡ºçš„æœ¯è¯­å‡†ç¡®ç¿»è¯‘æˆâ€œ{target_language}â€ã€‚
3.  **æ ‡æ³¨ç±»å‹**ï¼šä¸ºæ¯ä¸ªæœ¯è¯­é™„ä¸Šç®€çŸ­çš„ç±»å‹æ³¨é‡Šï¼ˆä¾‹å¦‚ï¼šâ€œå¥³æ€§äººåâ€ã€â€œåœ°åâ€ã€â€œç»„ç»‡â€ã€â€œç‰©å“â€ï¼‰ã€‚
###è¾“ä»¥textareaæ ‡ç­¾è¾“å‡º
<textarea>
åŸæ–‡1|è¯‘æ–‡1|æ³¨é‡Š1
åŸæ–‡2|è¯‘æ–‡2|æ³¨é‡Š2
...|...|...
</textarea>"""
            messages = [{"role": "user", "content": user_content}]

            # æ¯æ¬¡è¯·æ±‚éƒ½è·å–ä¸€æ¬¡é…ç½®ï¼Œä»¥ç¡®ä¿èƒ½è½®è¯¢API Key
            platform_config = config.get_platform_configuration("translationReq")
            
            print(f"â”œâ”€ æ­£åœ¨å‘AIå‘é€è¯·æ±‚ (å…± {len(batch_contexts)} è¡Œ)...\n")
            requester = LLMRequester()
            skip, _, response_content, _, _ = requester.sent_request(
                messages, system_prompt, platform_config
            )

            if skip or not response_content:
                self.error(f"ç¬¬ {batch_num} æ‰¹æ¬¡è¯·æ±‚å¤±è´¥æˆ–è¿”å›å†…å®¹ä¸ºç©ºã€‚")
                print(f"â””â”€ âŒ è¯·æ±‚å¤±è´¥æˆ–æ— å›å¤ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                return [] # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºå¤±è´¥

            print("â”œâ”€ æ”¶åˆ°å›å¤ï¼Œæ­£åœ¨è§£æ...")
            
            try:
                match = re.search(r'<textarea>(.*?)</textarea>', response_content, re.DOTALL)
                if not match:
                    self.warning(f"ç¬¬ {batch_num} æ‰¹æ¬¡å›å¤ä¸­æœªåŒ¹é…åˆ° <textarea> å—ã€‚")
                    print(f"â””â”€ âš ï¸ å›å¤ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæœ¯è¯­å—ã€‚")
                    return []

                content_block = match.group(1).strip()
                lines = content_block.split('\n')
                
                batch_parsed_terms = []
                warnings_in_batch = False

                for line in lines:
                    line = line.strip()
                    if not line: continue
                    
                    parts = line.split('|')
                    if len(parts) == 3:
                        src, dst, info = [p.strip() for p in parts]
                        if src:
                            batch_parsed_terms.append({"src": src, "dst": dst, "info": info})
                    else:
                        self.warning(f"è§£æå¤±è´¥ï¼Œæ‰¹æ¬¡ {batch_num} ä¸­æ ¼å¼ä¸ç¬¦: {line}")
                        warnings_in_batch = True
                
                print(f"â”œâ”€ æœ¬æ‰¹æ¬¡æˆåŠŸè§£æ {len(batch_parsed_terms)} æ¡æœ¯è¯­ã€‚")
                if warnings_in_batch:
                    print(f"â””â”€ âš ï¸ æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œä½†æœ‰è§£æè­¦å‘Šã€‚")
                else:
                    print(f"â””â”€ âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆã€‚")
                
                return batch_parsed_terms
            except Exception as e:
                self.error(f"è§£æç¬¬ {batch_num} æ‰¹æ¬¡å“åº”æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
                print(f"â””â”€ âŒ è§£ææ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡ã€‚")
                return []

        all_parsed_terms = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰¹æ¬¡
        with ThreadPoolExecutor(max_workers=max_threads) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = []
            for i in range(num_batches):
                start_index = i * MAX_LINES
                end_index = start_index + MAX_LINES
                batch_contexts = unique_contexts[start_index:end_index]
                # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                future = executor.submit(process_batch, batch_contexts, i + 1, num_batches)
                futures.append(future)
            
            # è·å–å·²å®Œæˆä»»åŠ¡çš„ç»“æœ
            for future in as_completed(futures):
                try:
                    # è·å–å·¥ä½œå‡½æ•°çš„è¿”å›ç»“æœ
                    batch_results = future.result()
                    if batch_results:
                        all_parsed_terms.extend(batch_results)
                except Exception as e:
                    self.error(f"ä¸€ä¸ªæœ¯è¯­ç¿»è¯‘æ‰¹æ¬¡åœ¨æ‰§è¡Œä¸­é‡åˆ°ä¸¥é‡é”™è¯¯: {e}")
        
        # åç»­å¤„ç†é€»è¾‘ä¿æŒä¸å˜
        print("") # åœ¨æ—¥å¿—æœ«å°¾æ·»åŠ ä¸€ä¸ªç©ºè¡Œï¼Œä½¿æ ¼å¼æ›´ç¾è§‚
        self.info("æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œæ­£åœ¨å°†ç»“æœä¿å­˜åˆ°æœ¯è¯­è¡¨...")
        if not all_parsed_terms:
            self.warning("æ‰€æœ‰æ‰¹æ¬¡å‡æœªèƒ½è§£æå‡ºä»»ä½•æœ‰æ•ˆæœ¯è¯­ã€‚ä»»åŠ¡ç»“æŸã€‚")
            self.emit(Base.EVENT.TERM_TRANSLATE_SAVE_DONE, {"status": "no_result", "message": "æœªè§£æåˆ°æœ‰æ•ˆæœ¯è¯­"})
            return

        # åŠ è½½é…ç½®æ–‡ä»¶
        app_config = self.load_config()
        prompt_dictionary_data = app_config.get("prompt_dictionary_data", [])
        
        # è·å–æ—§æœ¯è¯­è¡¨ä¿¡æ¯
        existing_srcs = {item['src'] for item in prompt_dictionary_data}
        
        # å¯¹æ¯”å»é‡
        added_count = 0
        unique_new_terms = {term['src']: term for term in all_parsed_terms}.values()

        for term in unique_new_terms:
            if term['src'] not in existing_srcs:
                prompt_dictionary_data.append(term)
                existing_srcs.add(term['src'])
                added_count += 1
        
        # æ›´æ–°ä¿å­˜æœ¯è¯­è¡¨é…ç½®
        app_config["prompt_dictionary_data"] = prompt_dictionary_data
        self.save_config(app_config)
        
        # æ—¥å¿—è¾“å‡º
        self.info(f"ğŸ³ æœ¯è¯­ç¿»è¯‘ä¸ä¿å­˜ä»»åŠ¡å·²å®Œæˆï¼æˆåŠŸæ·»åŠ  {added_count} ä¸ªæ–°æœ¯è¯­åˆ°æœ¯è¯­è¡¨ã€‚")
        self.emit(Base.EVENT.TERM_TRANSLATE_SAVE_DONE, {
            "status": "success", 
            "message": f"æˆåŠŸæ·»åŠ  {added_count} ä¸ªæ–°æœ¯è¯­ã€‚",
            "added_count": added_count
        })